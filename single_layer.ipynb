{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Hidden Layer Trial\n",
    "### Compositional Lyapunov function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.keras.backend as kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the vector field\n",
    "# this is actually a form that gives a compositional lyapunov function\n",
    "# it is equation 7.1 from the grune paper\n",
    "def vf(x):\n",
    "    y = [-x[:,0]-10.*x[:,1]**2,-2.*x[:,1]]\n",
    "    return y\n",
    "\n",
    "\n",
    "# # this is equation 29 from main paper\n",
    "# def vf(x):\n",
    "#     y = [-x[:,1], x[:,0] + (1-x[:,0]**2)*x[:,1]]\n",
    "#     return y\n",
    "\n",
    "\n",
    "# define the upper bound for the boundary condition\n",
    "def upperbound(data):\n",
    "    return 10.*data[:,0]**2 + 10.*data[:,1]**2\n",
    "\n",
    "# define the lower bound for the boundary condition\n",
    "def lowerbound(data):\n",
    "    return 0.1*data[:,0]**2 + 0.1*data[:,1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "inputdim = 2\n",
    "data = 2.*np.random.random((200000, inputdim)) - 1\n",
    "ubound = upperbound(data)\n",
    "lbound = lowerbound(data)\n",
    "vfdata = vf(data)\n",
    "\n",
    "tdata   = tf.convert_to_tensor(data,   dtype=tf.float32)\n",
    "tubound = tf.convert_to_tensor(ubound, dtype=tf.float32)\n",
    "tlbound = tf.convert_to_tensor(lbound, dtype=tf.float32)\n",
    "tvf     = kb.transpose(tf.convert_to_tensor(vfdata, dtype=tf.float32))\n",
    "tzeros  = kb.zeros(tubound.shape)\n",
    "\n",
    "# usually we have x_train, y_train\n",
    "train_dataset_raw = tf.data.Dataset.from_tensor_slices((tdata, tubound, tlbound, tvf, tzeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 2), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 2), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shuffle_and_batch_dataset(dataset, batch_size, shuffle_buffer=None):\n",
    "    \"\"\"\n",
    "    This function is used to shuffle and batch the dataset, using shuffle_buffer\n",
    "    and batch_size.\n",
    "    Your function should return the shuffled and batched Dataset.\n",
    "    \"\"\"\n",
    "    if shuffle_buffer:\n",
    "        dataset = dataset.shuffle(buffer_size=shuffle_buffer)\n",
    "        \n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    return(dataset)\n",
    "\n",
    "train_dataset = shuffle_and_batch_dataset(train_dataset_raw, 32, shuffle_buffer=1024)\n",
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compile_and_fit_args():\n",
    "    \"\"\"\n",
    "    This function is used to create the optimizer, loss, metric and callback objects. \n",
    "    Each of these should be created as instances from the corresponding classes in the\n",
    "    optimizers, losses and metrics modules respectively, with the options as above.\n",
    "    The function should then return the tuple (optimizer, loss, metric, callback)\n",
    "    \"\"\"\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "    # opt = tf.keras.optimizers.SGD(learning_rate=0.0005)\n",
    "    # opt = 'sgd'\n",
    "    # loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    # loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "    loss = tf.keras.losses.MeanSquaredError()\n",
    "    # loss='sparse_categorical_crossentropy'\n",
    "    # acc = tf.keras.metrics.BinaryAccuracy()\n",
    "    # acc = tf.keras.metrics.Accuracy()\n",
    "    acc = 'accuracy'\n",
    "    earlystopping = tf.keras.callbacks.EarlyStopping(patience=200)\n",
    "    return opt, loss, acc, earlystopping\n",
    "\n",
    "\n",
    "def compile_and_fit(model, optimizer, loss, num_epochs, train_dataset, \n",
    "                    validation_dataset=None, metrics=None, callbacks=None):\n",
    "    \"\"\"\n",
    "    This function should compile and fit the model according to the above specifications.\n",
    "    It should then return the History object returned by the fit method\n",
    "    \"\"\"\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    history = model.fit(train_dataset, epochs=num_epochs, verbose=1,\n",
    "                        validation_data=validation_dataset, callbacks=callbacks)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " state (InputLayer)          [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                96        \n",
      "                                                                 \n",
      " Lyapunov_function (Dense)   (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 129\n",
      "Trainable params: 129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_regularised_bn_mlp(input_shape, hidden_units, l2_reg_coeff = None, dropout_rate = None):\n",
    "    \"\"\"\n",
    "    This function is used to build the MLP model. It takes input_shape and hidden_units\n",
    "    as arguments, which should be used to build the model as described above, using the\n",
    "    functional API.\n",
    "    Your function should return the model.\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape, name = 'state')\n",
    "    # h = inputs\n",
    "    h = tf.keras.layers.Dense(32, activation='linear')(inputs)\n",
    "    for units in hidden_units:\n",
    "        # h = tf.keras.layers.Dense(units, activation='selu', \n",
    "        #                           kernel_regularizer=tf.keras.regularizers.l2(l2_reg_coeff))(h)\n",
    "        h = tf.keras.layers.Dense(units, activation='linear')(h)\n",
    "        # h = tf.keras.layers.BatchNormalization()(h)\n",
    "        # h = tf.keras.layers.Dropout(dropout_rate)(h)\n",
    "    # outputs = tf.keras.layers.Dense(10, activation=None)(h)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='linear', name = 'Lyapunov_function')(h)\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "model = get_regularised_bn_mlp(input_shape=inputdim, hidden_units=[])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/lysi2/Documents/UNI_Imperial/Deep_Learning/DL/lib/python3.7/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/lysi2/Documents/UNI_Imperial/Deep_Learning/DL/lib/python3.7/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/lysi2/Documents/UNI_Imperial/Deep_Learning/DL/lib/python3.7/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/lysi2/Documents/UNI_Imperial/Deep_Learning/DL/lib/python3.7/site-packages/keras/engine/training.py\", line 805, in train_step\n        x, y, sample_weight = data_adapter.unpack_x_y_sample_weight(data)\n    File \"/Users/lysi2/Documents/UNI_Imperial/Deep_Learning/DL/lib/python3.7/site-packages/keras/engine/data_adapter.py\", line 1581, in unpack_x_y_sample_weight\n        raise ValueError(error_msg)\n\n    ValueError: Data is expected to be in format `x`, `(x,)`, `(x, y)`, or `(x, y, sample_weight)`, found: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 2) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, <tf.Tensor 'IteratorGetNext:3' shape=(None, 2) dtype=float32>, <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zg/b63jfq5j6pzb4_lby01nk6_m0000gn/T/ipykernel_2469/934456749.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     metrics=[bin_acc])\n\u001b[0m",
      "\u001b[0;32m/var/folders/zg/b63jfq5j6pzb4_lby01nk6_m0000gn/T/ipykernel_2469/762926316.py\u001b[0m in \u001b[0;36mcompile_and_fit\u001b[0;34m(model, optimizer, loss, num_epochs, train_dataset, validation_dataset, metrics, callbacks)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     history = model.fit(train_dataset, epochs=num_epochs, verbose=1,\n\u001b[0;32m---> 30\u001b[0;31m                         validation_data=validation_dataset, callbacks=callbacks)\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/UNI_Imperial/Deep_Learning/DL/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/UNI_Imperial/Deep_Learning/DL/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/lysi2/Documents/UNI_Imperial/Deep_Learning/DL/lib/python3.7/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/lysi2/Documents/UNI_Imperial/Deep_Learning/DL/lib/python3.7/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/lysi2/Documents/UNI_Imperial/Deep_Learning/DL/lib/python3.7/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/lysi2/Documents/UNI_Imperial/Deep_Learning/DL/lib/python3.7/site-packages/keras/engine/training.py\", line 805, in train_step\n        x, y, sample_weight = data_adapter.unpack_x_y_sample_weight(data)\n    File \"/Users/lysi2/Documents/UNI_Imperial/Deep_Learning/DL/lib/python3.7/site-packages/keras/engine/data_adapter.py\", line 1581, in unpack_x_y_sample_weight\n        raise ValueError(error_msg)\n\n    ValueError: Data is expected to be in format `x`, `(x,)`, `(x, y)`, or `(x, y, sample_weight)`, found: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 2) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, <tf.Tensor 'IteratorGetNext:3' shape=(None, 2) dtype=float32>, <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "opt, bce_loss, bin_acc, early_stopping = get_compile_and_fit_args()\n",
    "\n",
    "history = compile_and_fit(model, \n",
    "                    optimizer=opt, \n",
    "                    loss=bce_loss, \n",
    "                    num_epochs=15, \n",
    "                    train_dataset=train_dataset, \n",
    "                    metrics=[bin_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ea4ae45c481d49b1f7ee32c400286c37e8040db9d409996f2cf49118c022492"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
